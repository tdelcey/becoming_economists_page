[
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "News",
    "section": "",
    "text": "Release of the french Ph.D. database (version 1.0)\n\n\n\n\n\n\n\n\n2024\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "News"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome in the website of the project “Becoming an economist”. This project is dedicated to the collection and analysis of bibliometric data on theses in economics in the 20th and 21st centuries across different countries. The team is actually working on three countries: France, the United States and the United Kingdom.\n\nLatest news\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRelease of the french Ph.D. database (version 1.0)\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n\n\n\n\n\n\n\n\n\n\nA topic model of French Ph.D. in economics\n\n\n\n\n\n\n\n\n\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "documentation/US/index.html",
    "href": "documentation/US/index.html",
    "title": "Documentation: the US database",
    "section": "",
    "text": "Work in progress"
  },
  {
    "objectID": "documentation/french/index.html#thesis-metadata",
    "href": "documentation/french/index.html#thesis-metadata",
    "title": "Documentation: the French database",
    "section": "Thesis Metadata",
    "text": "Thesis Metadata\nThe thesis metadata table contains 15 variables:\n\nthesis_id: the unique identifier of the thesis. If it exists, it is the officiel “national number of the thesis” created by the Agence Bibliographique de l’Enseignement Supérieur (ABES) and the theses.fr website. If not, it is a temporary identifier we have created.\nyear_defence: the date of the defence of the thesis. It covers the period between 1899 and 2023.\nlanguage_1 and language_2 are the languages of the thesis. It is a harmonized variables of the respective language variables found in SUDoc and These.fr.\ntitle_fr: the title of the thesis in French.\ntitle_en: the title of the thesis in English.\ntitle_other: the title of the thesis in another language.\nabstract_fr: the abstract of the thesis in French.\nabstract_en: the abstract of the thesis in English.\nabstract_other: the abstract of the thesis in another language.\nfield: the field of the thesis. It is a harmonized variable of the respective field variables found in SUDoc and These.fr.\naccessible: a binary variable indicating whether the fulltext is accessible or not.\ntype: the type of the thesis. Type can take 6 values: Thèse, Thèse de 3e cycle, Thèse de docteur-ingénieur, Thèse d’État, Thèse complémentaire, Thèse sur travaux. All categories are categories found in SUDoc (see Tip 1).\ncountry: the country where the thesis was defended (à supprimer ?)\nurl: the url of the thesis, linking to the theses.fr website or the sudoc.fr website.\n\n\n\n\n\n\n\nWarning\n\n\n\nRaw source data had an important rate of error in the title and abstract language: title in french were in the english column and vice versa. We have corrected this issue by using a language prediction model. The model is based on a combination of language predictive models to predict the language of abstracts and relocate abstracts in proper columns. See Section 4.7.4 for details.\n\n\nTable 1 shows a sample of the thesis metadata table. The thesis metadata table contains 21025 theses. Figure 1 shows the distribution of theses over time.\n\n\n\n\nTable 1: Sample of the metadata table\n\n\n\n\n\n\n\n\n\n\n\nDistributionDistribution by type of thesis\n\n\n\n\n\n\n\n\n\n\nFigure 1: Distribution of theses by defense date\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Distribution of theses by defense date and type of thesis\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote 1: Type of theses in the French system\n\n\n\nNote that the French education system did not have a harmonized Ph.D. system between the early 1960s and 1984, date of the Sauvy reform that harmonized the Ph.D. system. During this period, various types of theses existed before. It was usual in the mid 1970s to start with a “Doctorat de 3e cycle” before making a “Doctorat d’Etat”. Thus, one author can have several types of theses. Figure 2 shows the distribution of theses over time by the type of thesis."
  },
  {
    "objectID": "documentation/french/index.html#edges",
    "href": "documentation/french/index.html#edges",
    "title": "Documentation: the French database",
    "section": "Edges",
    "text": "Edges\nEach line in the edge table is a unique edge between a thesis and an entity. We define entity as any individual or institution involved in the thesis. The edge table has 6:\n\nthesis_id: the identifiers of a thesis (the same than in thesis_medata). In the edge table, a thesis_id can have several edges. A thesis_id has at least two edges: the author and the institution in which the thesis was defended.\nentity_id: the identifiers of an entity.\nentity_role: the role of the entity. A person can be either an author, a supervisor, a referee, a president or a member of jury. In addition to the main institution in which the Ph.D. was defended, the entity_role can contain additional information we were able to collect such as the other institutions, laboratories, doctoral schools (the institution organizing the doctorate in french university). Note that it concerns only theses collected in these.fr after 1985. For SUDoc, the value etablissements_soutenance_from_info may provide additional information on the institution.\nentity_firstname: The name of the entity. Each entity has a entity_name. Note that the entity identifiers is unique but the entity name is not unique. For instance, two different persons can have the same name. When available, an individual can have a entity_firstname.\n\n\n\n\n\n\n\nWarning\n\n\n\nMost of our effort in building the database was to delete duplicates in entities so that users can easily estimate the involvement of an entity in theses. It is the case for most institutions which are well identified by an unique idref. Unfortunately, it was impossible to disambiguous all entities for individuals. To illustrate this point, it is very easy to spot that the string “Paris I” and “Paris I Panthéon-Sorbonne” are the same entity but we cannot be sure that “Thomas Delcey” authoring a Ph.D in 2021 is the same person than “Thomas Delcey” supervising a Ph.D. in 2022. The variable homonym_of allows the user to spot potential duplicates. See details in Section 4.7.6.\n\n\nTable 2 shows a sample of the thesis edge table. We identify 108221 edges in total. Figure 3 shows the distribution of individuals by role. Figure 4 shows the distribution of individuals for the top institutions.\n\n\n\n\nTable 2: Sample of the edges table\n\n\n\n\n\n\n\n\n\n\n\nTop rolesTop institutions\n\n\n\n\n\n\n\n\n\n\nFigure 3: Top role\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Top role"
  },
  {
    "objectID": "documentation/french/index.html#institutions",
    "href": "documentation/french/index.html#institutions",
    "title": "Documentation: the French database",
    "section": "Institutions",
    "text": "Institutions\nThe thesis institution table contains 1790 institutions. Institutions are the universities, laboratories, doctoral schools, and other institutions associated with the theses.\nThe thesis institution table contains 19 variables. It consists of two core variables:\n\nentity_id: the unique identifier of the entity (here the institution).\nentity_name: the name of the entity.\n\nThe other variables are additional information on the institution provided by the IdRef database:\n\nurl: the url of the entity.\nscraped_id: the identifier of the entity in the scraped data.\npref_name: the preferred name of the entity.\nother_labels: other labels of the entity.\ncountry: the country of the entity.\ndate_of_birth: the date of birth of the entity.\ndate_of_death: the date of death of the entity.\ninformation: additional information on the entity.\nreplaced_idref: the identifier of the entity that replaced the entity.\npredecessor: the predecessor of the entity.\npredecessor_idref: the identifier of the predecessor of the entity.\nsuccessor: the successor of the entity.\nsuccessor_idref: the identifier of the successor of the entity.\nsubordinated: the subordinated entity.\nsubordinated_idref: the identifier of the subordinated entity.\nunit_of: the unit of the entity.\nunit_of_idref: the identifier of the unit of the entity.\nother_link: other links of the entity.\ninfo: additional information on the entity.\ncountry_name: the country name of the entity.\n\nTable 3 shows a sample of the thesis institution table.\n\n\n\n\nTable 3: Sample of the thesis institution table"
  },
  {
    "objectID": "documentation/french/index.html#individuals",
    "href": "documentation/french/index.html#individuals",
    "title": "Documentation: the French database",
    "section": "Individuals",
    "text": "Individuals\nThe thesis person table contains 14 variables. The four core variables are:\n\nentity_id: the unique identifier of the individual.\nentity_name: the name of the individual.\nentity_firstname: the first name of the individual.\ngender: the gender of the individual according to the IdRef database.\ngender_expanded: the gender of the individual according to the IdRef database augmented for missing values with the French census data (see details in Section 4.7.5).\n\nThe other variables are additional information on the individual provided by the IdRef database:\n\nbirth: the birth date of the individual.\ncountry: the country of the individual.\ninfo: additional information on the individual.\norganization: the organization of the individual.\nlast_date_org: the last date of the organization.\nstart_date_org: the start date of the organization.\nend_date_org: the end date of the organization.\nother_link: other links of the individual.\ncountry_name: the country name of the individual.\nhomonym_of: the identifier of the homonyms in the database.\n\nTable 4 shows a sample of the thesis metadata table.\n\n\n\n\nTable 4: Sample of the thesis person table\n\n\n\n\n\n\n\n\n\n\n\nGenderCountry\n\n\n\n\n\n\n\n\n\n\nFigure 5: Distribution of individuals by gender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Distribution of individuals by country (top 10 excluding France)"
  },
  {
    "objectID": "documentation/french/index.html#general-presentation",
    "href": "documentation/french/index.html#general-presentation",
    "title": "Documentation: the French database",
    "section": "General presentation",
    "text": "General presentation"
  },
  {
    "objectID": "documentation/french/index.html#data-sources",
    "href": "documentation/french/index.html#data-sources",
    "title": "Documentation: the French database",
    "section": "Data sources",
    "text": "Data sources\nThe data used in this project comes from three mains sources:\n\nTheses.fr: https://theses.fr/\nSUDoc: https://www.sudoc.fr/\nIdRef: https://www.idref.fr/\n\nThese sources are the result of the work of the ABES (l’Agence bibliographique de l’enseignement supérieur) who produced metadata and APIs regarding research and superior education. The data of the three sources mentionned above are under the Etabab “Open Licence”.1\n\nTheses.fr:\nTheses.fr is a comprehensive repository for PhD dissertations defended in French institutions since 1985.2 It includes metadata such as the title of the dissertation, author, date of defense, institution, supervisor, abstract, etc.. The database covers a wide range of disciplines, providing access, in some cases, to digital theses.\n\n\nSUDoc (Système Universitaire de Documentation):\nSUDoc is a union catalog that includes references to various documents held in French academic and research libraries. It covers books, journal articles, dissertations, and other academic works. The SUDoc database includes metadata like title, author, publication date, and library locations where the documents can be found. It’s a key resource for academic research in France, providing a broad overview of available scholarly materials. Regarding PhD, it allows to find dissertations defended before 1985, and to recover relevant metadata.\n\n\nIdRef (Identifiants et Référentiels pour l’Enseignement supérieur et la Recherche):\nIdRef is a database focused on managing and standardizing the names and identifiers of authors and other contributors to academic and research works. It provides authority control for names used in academic cataloging, ensuring consistency and aiding in accurate attribution of works. IdRef is used in conjunction with SUDoc and other databases to support the management of bibliographic data in the French higher education and research sectors. In our project, it allows us to find additional data on individuals and institutions."
  },
  {
    "objectID": "documentation/french/index.html#data-collection",
    "href": "documentation/french/index.html#data-collection",
    "title": "Documentation: the French database",
    "section": "Data collection",
    "text": "Data collection"
  },
  {
    "objectID": "documentation/french/index.html#theses.fr-1",
    "href": "documentation/french/index.html#theses.fr-1",
    "title": "Documentation: the French database",
    "section": "theses.fr",
    "text": "theses.fr\nTheses records are registered in theses.fr since 1985. Theses.fr data are also stored on data.gouv.fr website. They can be downloaded directly at this URL. The downloading_theses_fr.R script allows to download the .csv on data.gouv and to compress and store it in .rds format."
  },
  {
    "objectID": "documentation/french/index.html#sudoc",
    "href": "documentation/french/index.html#sudoc",
    "title": "Documentation: the French database",
    "section": "SUDoc",
    "text": "SUDoc\nWe systematically collect metadata on French dissertations archived in the SUDoc database, focusing on theses in economics through two distinct query strategies:\n\nFirst query: We search for dissertations with a term starting with “econo” in the “Note de Thèse” field, which denotes the thesis discipline. This keyword captures terms like “économie” or “Economique” since SUDoc ’s search function is case-insensitive and ignores accents. The time frame is limited to 1900–1985, as dissertations from later years are systematically cataloged in Theses.fr. Here is the query, allowing to retrieve thesis records.\nSecond query: We search for dissertations where “droit” (law) is specified in the “Note de Thèse” field, and where a term starting with “econo” appears in the title. This search is limited to 1900-1968 to capture dissertations classified as law theses before 1968 that likely focus on economics. Here is the query, allowing to retrieve thesis records.\n\nThe scraping_sudoc_id.R collects the thesis records URLs. Then, the scraping_sudoc_api.R allows to query the SUDoc API to retrieve structured metadata for each thesis, including information such as title, author, defence date, abstract, supervisor and other relevant details. These metadata are stored in an .xml file, which we then parse to extract the relevant information. The .xml is structured according to “tags” and “codes” that are explained here."
  },
  {
    "objectID": "documentation/french/index.html#idref",
    "href": "documentation/french/index.html#idref",
    "title": "Documentation: the French database",
    "section": "IdRef",
    "text": "IdRef\nThe IdRef platform serves as a rich repository of structured metadata for individuals and institutions linked to academic records in France, particularly those cataloged in SUDoc and Thèses.fr. By leveraging unique IdRef identifiers, we can extract detailed information about individuals (e.g., date of birth, nationality, gender, last known institutions) and institutions (e.g., institutions preferred and alternate names, years of existence) involved in the Ph.D. graduating process. This helps to standardize individuals and institutions names and to ensure consistency and complete missing information for certain theses records."
  },
  {
    "objectID": "documentation/french/index.html#data-cleaning",
    "href": "documentation/french/index.html#data-cleaning",
    "title": "Documentation: the French database",
    "section": "Data cleaning",
    "text": "Data cleaning\nOur data-cleaning approach focuses on ensuring consistency and quality while preserving the integrity of the original data. Key information, such as the institution of the thesis, is standardized to facilitate analysis. However, we keep this standardized data separate from the raw data, ensuring transparency in our modifications and avoiding any loss of original information.\nThe first step of the cleaning process involves merging data extracted from Theses.fr and SUDoc. We ensure compatibility in the metadata format and structure, allowing for a seamless integration of the two datasets. After merging, the dataset is organized into three main components:\n\nThesis Metadata: This component contains core details about each thesis. Each line represents a thesis record, including information such as the title, defense date, abstract, and other relevant details.\nIndividual Data: Each line represents an individual involved in the thesis, such as authors, supervisors, or jury members.\nInstitutions Data: This includes all mentioned universities, laboratories, doctoral schools, and other institutions associated with the theses.\n\nThis relational database connecting different data frames facilitates well-structured, accurate analysis across different dimensions of the dataset (see the Description of the database section for details on the final content of the database).\n\nCleaning SUDoc data\nThe cleaning process for SUDPC data in 1_FR_sudoc_cleaning.R is designed to address inconsistencies, remove duplicates, and standardize information across the dataset. This step aims to correct errors and inconsistencies linked to the SUDoc extraction, as well as to allows the consistency and merging with theses.fr data. Further cleaning steps are necessary and implemented after this merging.\n\nDuplicate Management\nThe cleaning process first identifies and resolves duplicate records, which fall into two categories:\n\nTrue duplicates: These occur when the same thesis is listed multiple times with identical identifiers and authors but differing defence dates. The process retains the most recent record as it is more likely to reflect the correct metadata.\nFalse duplicates: These occur when the same identifier is shared by different authors, often due to data entry errors. To resolve these, unique identifiers are created by appending a counter to the nnt, ensuring data integrity without introducing ambiguity.\n\n\n\nDate Standardization\nDefence dates (year_defence) are cleaned and standardized by: - Choosing the oldest date for theses with multiple dates, as the earliest date is more likely to reflect the actual defence event. - Flagging and logging anomalous dates outside the query range (1899–1985) or those with large gaps between associated dates for manual inspection.\nThis approach minimizes errors stemming from incomplete or conflicting date records and ensures chronological accuracy.\n\n\nStandardization of thesis types and Languages\nThesis types are deduplicated and recoded into consistent categories (e.g., “Thèse d’État”, “Thèse de 3e cycle”). Records that are not doctoral theses (e.g., master’s dissertations) are filtered out to focus exclusively on relevant entries. Similarly, language codes are standardized to align with ISO conventions and ensure compatibility with related datasets.\n\n\nOutput Preparation\nThe final dataset is split into four distinct outputs:\n\nMetadata Table: Core information about theses, such as titles, abstracts, dates, and types.\nEdge Table: Links between theses and associated entities (individuals and institutions).\nPerson Table: A unique list of individuals involved in theses (authors, jury members, etc.).\nInstitution Table: A unique list of institutions linked to theses (universities, laboratories, etc.).\n\nBy structuring the cleaned data in this way, the workflow facilitates downstream analysis, such as network modeling and bibliometric studies, while maintaining transparency in data transformations. This cleaning pipeline ensures the dataset’s reliability and usability for academic and research purposes.\n\n\n\nCleaning Theses.fr data\nThe 2_FR_thesesfr_cleaning.R is dedicated to cleaning and structuring metadata for theses related to economics extracted from the Theses.fr database. The primary goal is to prepare the dataset for integration with SUDoc data.\nThe cleaning process begins with filtering the dataset to retain only theses categorized under economics disciplines. A simple keyword search (e.g., “econom” or “économ”) identifies potential entries, followed by the exclusion of specific fields unrelated to economics (e.g., legal or geographic disciplines, like “Droit économique”). Additionally, basic data quality checks ensure that all entries have valid and unique identifiers (nnt) to prevent issues during downstream processing.\nThe cleaned dataset is then divided into structured components for better usability. The metadata table (thesesfr_metadata) includes core thesis attributes such as titles, abstracts, defense dates, and disciplines. The edge table (thesesfr_edge) captures relationships between theses and associated entities, including authors, jury members, and affiliated institutions. Separate tables for individuals (thesesfr_person) and institutions (thesesfr_institution) are derived from the edge table. Temporary IDs are generated for entities without official identifiers to facilitate later identification and disambiguation.\n\n\nMerging theses.fr and SUDoc data\nThe 3_FR_merging_database.R script consolidates data from the two primary sources, SUDoc and Theses.fr, to create unified datasets. The process involves merging metadata, relationships (edges), individuals, and institutions while resolving duplicate entries across sources. Metadata is harmonized by removing redundancies and retaining unique thesis identifiers. Edge tables are cleaned to link theses with associated individuals and institutions, ensuring consistent identifiers for entities that appear in both databases. Separate tables for individuals and institutions are deduplicated and aligned for further cleaning and standardization.\n\n\nCleaning thesis metadata\nThe 4_FR_cleaning_thesis_metadata.R is designed to clean and standardize metadata for theses, with a primary focus on managing titles and abstracts. The modification implemented in this script directly transformed the original columns, but all transformations are checked by eye and does not change the informational content of the columns. More directly: it mainly corrects errors in the original recording of information in SUDOC and Theses.fr.\nThe script addresses several key challenges: - the normalization of formatting the titles and abstracts - the detection and imputation of missing values - the verification of language consistency and the reallocation of misplaced titles and abstracts - the identification of duplicate thesis records\nA central component of the script is the cleaning of titles and abstracts. Titles and abstracts written in full uppercase are transformed into sentence case to enhance readability. Placeholder text and irrelevant symbols are also removed, with problematic entries replaced by missing values (NA).\nFor cases where either French or English titles and abstracts are missing, the script employs auxiliary columns originally scraped (title_other and abstract_other) to fill gaps when relevant. Indeed, language detection is used to validate these imputed values, leveraging both the cld3 [@R-cld3] and fastText [@fastText2016b] models for robust identification.\nLanguage consistency is verified across the metadata. Titles and abstracts are checked to ensure that French and English columns contain text matching their intended language. Discrepancies are resolved by reassigning text to the correct fields.\n\n\nCleaning institutions\nThe 5_FR_cleaning_institution.R script aims to standardize and improve the quality of institution data. So far, any institution names mentioned in the metadata have been extracted and stored in a separate table. This script focuses on cleaning and standardizing these names to ensure consistency and accuracy in the dataset. Our goal is to replace temporary institution identifiers (id_temp) we have created in 3_FR_merging_database.R with the official IdRef identifiers (id_ref) to ensure consistency and accuracy in the dataset.\nThis replacement relies on matching the institution names and thesis defense dates. The process accounts for historical changes in institutional structures (e.g., the splitting of the University of Paris after 1968), ensuring that ambiguous cases are handled carefully. The core of the script is a manually defined table that associates regular expressions (regex) for institution names with their corresponding idref identifiers. This table also includes the dates of creation (date_of_birth) and dissolution (date_of_death) of institutions to set clear boundaries for replacement. For instance, if an institution’s name matches “University of Paris” and the thesis was defended before 1970, the identifier is replaced with that of the historic University of Paris, as it was the only university in Paris at the time.\nThis approach ensures that institution identifiers are accurate and consistent across the dataset, enabling robust analysis and interpretation of the data. We kept the temporary identifier and did not assign an idref institution names when we were enable to resolve the ambiguity. For instance, if the institution is the “University of Paris” for a thesis defended after 1968 (and that could be Paris 1, Paris 2, Paris 3, etc.) we kept the temporary identifier. Each ambigous entity name kept its temporary identifier even when the name is the same.\n\n\nCleaning individuals\nThe 6_FR_cleaning_persons.R script focuses on standardizing and improving the quality of individual data.\nFirst, this script processes and cleans data for individuals associated with theses by merging and normalizing information of persons (e.g., authors, supervisors, etc.) from the idref_person_table. When a name entity is associated to an idref identifier, the script adds supplementary information on the person provided by the IdRef database (organization, birth date, relevant links such as wikipedia pages, etc.).\nSecond, we try to clean and unify person identifiers. We know that the same person can have slightly different names (e.g., “Jean A. Dupont” and “Jean Dupont”) or that the same person can have the same names but different identifiers. It is particularly the case for person present in both SUDoc and Theses.fr databases. For instance, the same person can be the author of a thesis in SUDoc and a member of the jury of another thesis. Contrary to institution tables, however, we are enable to replace temporary identifiers by idref identifiers for individuals because of the risk of homonyms. If two persons have the same name, we cannot be sure that they are the same person. Two authors of two different theses could have the same name or it could be the same person doing two theses.\nTo address this issue, we create a new column homonym_of that group potential homonyms. For each person, the variable homonym_of give the list of person identifiers that are her homonyms. a new column homonym_of that group potential homonyms. For each person, the variable homonym_of give the list of person identifiers that are her homonyms."
  },
  {
    "objectID": "documentation/french/index.html#application-to-other-disciplines",
    "href": "documentation/french/index.html#application-to-other-disciplines",
    "title": "Documentation: the French database",
    "section": "Application to other disciplines",
    "text": "Application to other disciplines\nNote that we focus on Ph.D. in economics but the project has been run with a relatively general perspective in mind, meaning that our codes could be transferred easily to other projects focusing on other disciplines in France. Indeed, a few changes in a couple of scripts would allow easily to scrape and clean the data for other disciplines or subjects. It would just involve:\n\nchanging the SUDoc queries in scraping_scrpits/scraping_SUDoc _id.R.\nchanging the theses.fr queries in cleaning_scripts/2_FR_thesefr_cleaning.R.\n\nSince the rest of the code aimed at standardizing, cleaning and merging data, it can be applied to any queries. Don’t hesitate to ask us for guidance if you are using our code to extract similar data."
  },
  {
    "objectID": "documentation/french/index.html#footnotes",
    "href": "documentation/french/index.html#footnotes",
    "title": "Documentation: the French database",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSee the English description of the licence here.↩︎\nThis corresponds to the reform of French PhD and the implementation of the “new regime”.↩︎"
  },
  {
    "objectID": "application.html",
    "href": "application.html",
    "title": "Application",
    "section": "",
    "text": "A topic model of French Ph.D. in economics\n\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Application"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "blablabla",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "application/french/index.html",
    "href": "application/french/index.html",
    "title": "A topic model of French Ph.D. in economics",
    "section": "",
    "text": "In this blog article, we explore together the French data. We exploit a textual variable, title_fr as the input of a classification model and we try to identify what can be viewed as trendy topics in French economics over the 20th century.\nWe use a probabilistic topic model from the stm R package. A probabilistic topic model is class of machine learning model that aimed at classifying (by topics) textual datasets. In a probabilistic topic model, the documents are represented as a mixture of \\(K\\) topics: for each documents, the model gives the probability that the document contained the topic \\(k \\in 1:K\\). This is called the topic prevalence or topic proportion, noted \\(\\theta_{1:D}\\) where \\(\\theta_{d}\\) is the probability distribution over topics for the document \\(d \\in 1:D\\). In a topic model, topics are themselves a mixture of words from the corpus vocabulary—the list of unique words used in the entire corpus. For each topics, the model gives the probability that the topic contained this word. This is called the topic content \\(\\beta_{1:K}\\) where \\(\\beta_{k}\\) is the probability distribution over the vocabulary for the topics \\(k\\).\nThese probabilities are estimated from a generative process. Intuitively, the topic model initializes a topic prevalence and a topic content, used them to generate a corpus of documents and confront it to the observed one to adjust the topic prevalence and topic content. The input to a topic model is the document frequency matrix (DFM), also called the document-term matrix, where rows represent documents, columns represent unique words in the vocabulary, and cell values indicate the frequency of each word in a given document. The model evaluates how well the current \\(\\theta_{1:D}\\) and \\(\\beta_{1:K}\\) predict word frequencies in the DFM and updates them.1\nOne of the main strength of this family of classification model is that the classification is unsupervised and do not depends of an a priori classification from the modelers. This feature is particularly useful for historical analysis. In classification tasks, there is always a risk of presentism, that is applying a anachronistic classification to the past. In a probabilistic topic model, you are not defining a priori a set of topics that you cannot know. You are rather generating topics using a set of priors on what is a topic (a distribution of words) and what is a document (a distribution of topics).\nThe stm package (Roberts et al. 2013) implemented a topic model whose main feature is to offer a framework to explore the relationship between the metadata of the document and the prevalence of topics. This feature is implemented in two central functions:\n\nthe function stm::stm() generates a topic model in which the prevalence can depend of a selected set of document metadata ;\nthe function stm::estimateEffect() estimates a regression of the estimated topic prevalence using a selected set of documents metadata.2\n\nBoth function are complementary. The metadata helps in training a topic model and in estimating the topic prevalence over documents whilst the regression analysis allows to measure precisely the controled effect of each metadata on topics prevalence.\nIn this blog, we will run a topic model and analyze the effect of two variables of the table metadata year_defence—how topics evolve over time—and gender—how topics are affected by the gender of Ph.D students."
  },
  {
    "objectID": "application/french/index.html#summary",
    "href": "application/french/index.html#summary",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Summary",
    "text": "Summary\n\n\nShow the code\nstm &lt;- readRDS(here(website_data_path, \"stm.rds\"))\n\nlabel_topic &lt;- labelTopics(stm, n = 5) \n\ntop_terms_prob &lt;- label_topic %&gt;% .[[1]] %&gt;% \n  as_tibble() %&gt;% \n  reframe(topic_label_prob = pmap_chr(., ~ paste(c(...), collapse = \", \"))) %&gt;% \n  mutate(topic = row_number()) \n\n# tidy call gamma the prevalence matrix, stm calls it theta  \ntheta &lt;- broom::tidy(stm, matrix = \"gamma\") %&gt;% \n  # broom called stm theta matrix gamma \n  left_join(top_terms_prob, by = \"topic\") \n\n#### plot summary of topics ####\n\ntheta_mean &lt;- theta %&gt;%\n  group_by(topic, topic_label_prob) %&gt;%\n  # broom called stm theta matrix gamma \n  summarise(theta = mean(gamma)) %&gt;%\n  ungroup %&gt;% \n  mutate(topic = reorder(topic, theta)) %&gt;% \n  slice_max(theta, n = 10)\n\ntheta_mean %&gt;%\n  ggplot() +\n  geom_segment(\n    aes(x = 0, xend = theta, y = topic, yend = topic\n  ),\n  color = \"black\",\n  size = 0.5) +\n  geom_text(\n    aes(x = theta, y = topic, label = topic_label_prob),\n    hjust = -.01,\n    nudge_y = 0.0005,\n    size = 4\n  ) + \n  scale_x_continuous(\n    expand = c(0, 0),\n    limits = c(0, max(theta_mean$theta) + 0.1),\n    labels = scales::percent_format()\n  ) +\n  ggthemes::theme_hc() +\n  theme(plot.title = element_text(size = 8)) +\n  labs(\n    y = expression(theta),\n    x = NULL,\n    caption =  \"Words are most probable words\"\n  )\n\n\n\n\n\n\n\n\nFigure 1: Top 10 topics by prevalence"
  },
  {
    "objectID": "application/french/index.html#corrélation-entre-thématiques",
    "href": "application/french/index.html#corrélation-entre-thématiques",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Corrélation entre thématiques",
    "text": "Corrélation entre thématiques\n\n\nShow the code\nstm &lt;- readRDS(here(website_data_path, \"stm.rds\"))\n\ncorr &lt;- stm::topicCorr(stm)\n\n# matric to table\ncorr_table &lt;- reshape2::melt(corr$cor) \n\n\nlabel_topic &lt;- labelTopics(stm, n = 10)\n\nnodes &lt;- label_topic %&gt;% .[[1]] %&gt;%\n  as_tibble() %&gt;%\n  reframe(topic_label_prob = pmap_chr(., ~ paste(c(...), collapse = \", \"))) %&gt;%\n  mutate(source_id = row_number()) \n\nedges &lt;- corr_table %&gt;% \n  dplyr::filter(Var1 != Var2) %&gt;% \n  rename(source_id = Var1,\n         target_id = Var2,\n         weight = value) \n\ngraph &lt;- tidygraph::tbl_graph(nodes = nodes, edges = edges, directed = FALSE)\n\n# if you want to normalize weigth to handle negative value \n\n# graph_normalize &lt;- graph %&gt;% \n#   activate(edges) %&gt;% \n#   mutate(weight = rescale(weight, to = c(0.01, 1)))\n\n\n# fa 2\ngraph_layout &lt;- vite::complete_forceatlas2(graph, first.iter = 50000, kgrav = 1)\n     \n\n#add leiden clusters \n# graph_cluster &lt;- networkflow::add_clusters(graph_layout,\n#                                            clustering_method = \"leiden\",\n#                                            objective_function = \"modularity\",\n#                                            resolution = 1)\nsaveRDS(corr_table, here(website_data_path, \"corr_table.rds\"))\n\nsaveRDS(graph_layout, here(website_data_path, \"graph_layout.rds\"))\n\n\n\nRéseau de corrélationDonnées\n\n\n\n\nShow the code\nlibrary(ggraph)\nlibrary(ggiraph)\n\ngraph_layout &lt;- readRDS(here(website_data_path, \"graph_layout.rds\"))\n\ngg &lt;- ggraph(graph_layout, \n             \"manual\", \n             x = x, \n             y = y) +\n  geom_edge_arc0(aes(\n          # color = cluster_leiden,\n          width = weight), \n          alpha = 0.1, strength = 0.2, show.legend = FALSE) +\n  scale_edge_width_continuous(range = c(0.1,0.3)) +\n  # scale_edge_colour_identity() +\n  geom_point(aes(x = x, y = y)) +\n  geom_label_repel_interactive(aes(x = x, \n                                   y = y, \n                                   # color = cluster_leiden,\n                                   label = source_id,\n                                   tooltip = topic_label_prob,\n                                   data_id = source_id)) +\n  scale_size_continuous(range = c(0.5,3)) +\n  # scale_fill_identity() +\n  labs(title = \"Les noeuds sont les thématiques, les liens sont les coefficients de corrélation.\") +\n  theme_void()\n\ngirafe(ggobj = gg,\n       width_svg  = 8,\n       height_svg = 4.5)\n\n\n\n\n\n\n\n\nFigure 2: Réseaux des thématiques (spacialisation par Force Atlas 2)\n\n\n\n\n\n\n\n\nShow the code\ncorr_table &lt;- readRDS(here(website_data_path, \"corr_table.rds\"))\n\n\ncorr_table %&gt;% \n  DT::datatable(\n  extensions = 'Buttons',\n  options = list(\n    dom = 'Blfrtip',\n    buttons = c('excel', 'csv'),\n    pageLength = 5\n  )\n)"
  },
  {
    "objectID": "application/french/index.html#regression-table",
    "href": "application/french/index.html#regression-table",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Regression table",
    "text": "Regression table\n\n\nShow the code\nestimate_effect &lt;- readRDS(here(website_data_path, \"estimate_effect.rds\"))\n\nsummary &lt;- summary(estimate_effect)\n\nsummary_tibble &lt;- summary$tables %&gt;% \n  purrr::imap_dfr(~ {\n    tibble(\n      topic = .y,  # Extract topic number\n      term = rownames(.x),  # Covariate names\n      estimate = .x[, 1],  # Coefficients\n      std_error = .x[, 2],  # Standard errors\n      t_value = .x[, 3],  # Confidence interval lower bound 95\n      p_value = .x[, 4]   # Confidence interval upper bound 95\n    )\n  })\n\nsummary_tibble %&gt;% \n  DT::datatable(\n  extensions = 'Buttons',\n  options = list(\n    dom = 'Blfrtip',\n    buttons = c('excel', 'csv'),\n    pageLength = 12\n  )\n)\n\n\n\n\nTable 1\n\n\n\n\n\nRégression de la prévalence avec interaction"
  },
  {
    "objectID": "application/french/index.html#effect-of-years",
    "href": "application/french/index.html#effect-of-years",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Effect of years",
    "text": "Effect of years\n\nTopTotal (individual plot)\n\n\n\n\nShow the code\n# function to estimate variation of theta between 1900 and \n\ndelta_theta &lt;- ee_date %&gt;%\n  group_by(topic) %&gt;% # Group by topic\n  reframe(delta = estimate[n()] - estimate[1]) # Difference between the last and first estimate)\n\nmax_delta &lt;- delta_theta %&gt;% slice_max(delta, n = 5)\n\ngg_max &lt;- ee_date %&gt;% \n  filter(topic %in% max_delta$topic) %&gt;%\n  ggplot(aes(\n      x = covariate.value,\n      color = paste0(topic, \" : \", topic_label_prob),\n    )) +\n    geom_line(aes(y = estimate)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n    labs(x = \"covariate.value\",\n         y = \"Expected topic prevalence\",\n         color = \"\") +\n    theme_minimal() +\n    theme(\n        strip.text = element_text(size = 3),\n        legend.position = \"bottom\",       # Positionne la légende en bas du graphique\n        legend.text = element_text(size = 8), # Ajuste la taille du texte dans la légende\n        legend.title = element_text(size = 9) # Ajuste la taille du titre de la légende\n    ) +\n    guides(color = guide_legend(nrow = 10)) # Place la légende sur une seule ligne\n\nmin_delta &lt;- delta_theta %&gt;% slice_min(delta, n = 5)\n\ngg_min &lt;- ee_date %&gt;% \n  filter(topic %in% min_delta$topic) %&gt;%\n  ggplot(aes(\n      x = covariate.value,\n      color = paste0(topic, \" : \", topic_label_prob),\n    )) +\n    geom_line(aes(y = estimate)) +\n    geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n    labs(x = \"covariate.value\",\n         y = \"Expected topic prevalence\",\n         color = \"\") +\n    theme_minimal() \n    # theme(\n    #     strip.text = element_text(size = 3),\n    #     legend.position = \"bottom\",       # Positionne la légende en bas du graphique\n    #     legend.text = element_text(size = 8), # Ajuste la taille du texte dans la légende\n    #     legend.title = element_text(size = 9) # Ajuste la taille du titre de la légende\n    # ) +\n    # guides(color = guide_legend(nrow = 10)) # Place la légende sur une seule ligne\n\nplotly::ggplotly(gg_min) %&gt;%\n  plotly::config(displayModeBar = FALSE)\nplotly::ggplotly(gg_max) %&gt;%\n  plotly::config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n(a) Top 5 negative variation between 1900 and today\n\n\n\n\n\n\n\n\n\n\n(b) Top 5 positive variation between 1900 and today\n\n\n\n\n\nFigure 3: Prediction of the expected topic proportion according to the year of defence\n\n\n\n\n\n\n\nTopic 1Topic 2Topic 3Topic 4Topic 5Topic 6Topic 7Topic 8Topic 9Topic 10Topic 11Topic 12Topic 13Topic 14Topic 15Topic 16Topic 17Topic 18Topic 19Topic 20Topic 21Topic 22Topic 23Topic 24Topic 25Topic 26Topic 27Topic 28Topic 29Topic 30Topic 31Topic 32Topic 33Topic 34Topic 35Topic 36Topic 37Topic 38Topic 39Topic 40Topic 41Topic 42Topic 43Topic 44Topic 45Topic 46Topic 47Topic 48Topic 49Topic 50Topic 51Topic 52Topic 53Topic 54Topic 55Topic 56Topic 57Topic 58Topic 59Topic 60Topic 61Topic 62"
  },
  {
    "objectID": "application/french/index.html#effect-of-gender",
    "href": "application/french/index.html#effect-of-gender",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Effect of gender",
    "text": "Effect of gender\n\nGender distributionData\n\n\n\n\nShow the code\ncorpus_in_stm &lt;- readRDS(here(website_data_path, \"corpus_in_stm.rds\"))\n\ngg &lt;- corpus_in_stm$meta  %&gt;% \n  group_by(gender_expanded, year_defence) %&gt;%\n  summarise(n = n()) %&gt;%\n  ungroup %&gt;%\n  mutate(tooltip = paste(\"Année:\", year_defence, \"&lt;br&gt;Nombre d'auteurs:\", n, \"&lt;br&gt;Genre:\", gender_expanded)) %&gt;%\n  ggplot(aes(\n    x = as.integer(year_defence),\n    y = n,\n    fill = gender_expanded,\n    text = tooltip\n  )) +\n  geom_col() +\n  theme_light() +\n  labs(x = \"\", y = \"Nombre d'auteurs\", fill = \"Genre\") +\n  scale_fill_brewer(palette = \"Set3\") +\n  theme_light()\n\nplotly::ggplotly(gg, tooltip = \"text\") %&gt;%\n  plotly::config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\nFigure 4: Distribution of authors by gender\n\n\n\n\n\n\n\n\nShow the code\ndata &lt;- corpus_in_stm$meta  %&gt;% \n  group_by(gender_expanded, year_defence) %&gt;%\n  summarise(n = n()) %&gt;%\n  ungroup \n\ndata %&gt;% \n  DT::datatable(\n  extensions = 'Buttons',\n  options = list(\n    dom = 'Blfrtip',\n    buttons = c('excel', 'csv'),\n    pageLength = 12\n  )\n)\n\n\n\n\nTable 2\n\n\n\n\n\nDistribution du genre par année\n\n\n\n\n\n\n\n\n\n\nShow the code\ngender_estimate &lt;- summary_tibble %&gt;% \n  filter(term == \"gender_expandedfemale\") \n\ngg &lt;- gender_estimate %&gt;%\n    mutate(tooltip = paste(\"Estimate:\", estimate)) %&gt;%\n  left_join(top_terms_prob, by = \"topic\") %&gt;%\n  mutate(\n    topic = reorder(topic, estimate),\n    effect = ifelse(estimate &gt; 0, \"Positive\", \"Negative\"),\n    effect = ifelse(p_value &gt;= .1, \"Not significant (90%)\", effect)\n  ) %&gt;% \n  filter(p_value &lt;= 0.1) %&gt;% \n  ggplot(aes(\n    x = topic,\n    y = estimate,\n    label = paste(topic, \"-\", topic_label_prob),\n    fill = effect,\n    text = tooltip\n  )) +\n  geom_col() +\n  geom_text(size = 2.5, position = position_stack(vjust = .5)) +\n  scale_fill_manual(\n    name = \"Effect\",\n    values = c(\n      \"Negative\" = \"#FFFFB3\",\n      \"Positive\" = \"#8DD3C7\",\n      \"Not significant (90%)\" = \"lightgrey\"\n    )\n  ) +\n  coord_flip() +\n  ggthemes::theme_hc() +\n  theme(plot.title = element_text(size = 15)) +\n  labs(x = NULL, y = \"Estimate\")\n\n\nplotly::ggplotly(gg, tooltip = \"text\") %&gt;%\n  plotly::config(displayModeBar = FALSE)\n\n\n\n\n\n\n\n\nFigure 5: Estimate effect of being a female author on topic prevalence\n\n\n\n\n:::"
  },
  {
    "objectID": "application/french/index.html#footnotes",
    "href": "application/french/index.html#footnotes",
    "title": "A topic model of French Ph.D. in economics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBlei (2012) give a comprehensive presentation of the generative and training process.↩︎\nA linear regression could be run using the standard statistics packages from R such as stats::lm(). However, contrary to a simple lm(theta ~ covariates), estimateEffect manages uncertainty measurement of the topic prevalence resulting from stm(). In a nutshell, instead of predicting the estimated prevalence \\(\\theta_d\\), it is predicting a set of simulated possible prevalences. The core of the methodology is contained in the stm::thetaPosterior() function available here.↩︎"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Data"
    ]
  },
  {
    "objectID": "documentation/UK/index.html",
    "href": "documentation/UK/index.html",
    "title": "Documentation: the UK database",
    "section": "",
    "text": "Work in progress"
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Documentation: the UK database\n\n\n\n\n\n\n\n\n2024\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentation: the US database\n\n\n\n\n\n\n\n\n2024\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nDocumentation: the French database\n\n\n\n\n\n\n\n\n2024\n\n\nThomas Delcey, Aurelien Goutsmedt\n\n\n28 min\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "news/french/index.html",
    "href": "news/french/index.html",
    "title": "Release of the french Ph.D. database (version 1.0)",
    "section": "",
    "text": "We are pleased to announce the release of the French database. This database contains information on all Ph.D. students who have defended their thesis in France since 1900. The database is available in CSV format and can be downloaded here. The documentation is available here."
  }
]